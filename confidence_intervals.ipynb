{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial demonstrates how to create confidence intervals for estimators.\n",
    "\n",
    "Suppose that there are two candidates, candidate A and candidate B, running for an election, and suppose that you want to determine the probability that candidate A will win, denoted as $p_A$. Suppose that a total of 100,000 people, also known as the population, can vote in this election. You could try and count the number of people in the population who will vote for candidate A, and then divide this by 100,000. However, this is not practical. Instead, you can select a small subset of the population, called a sample, and count how many of them will vote for candidate A and divide that by the sample size. This is called a **point estimate** of $p_A$. Suppose that you select a sample of 1,000 people.\n",
    "\n",
    "Let $X_i$ be $1$ if the $i^{th}$ person in the sample will vote for candidate A, and let $X_i$ be 0 if the $i^{th}$ person in the sample will vote for candidate B, for $i = 1,2,...,1000$. Since the sample's voting choices are random, then $X_1,X_2,...,X_{1000}$ are all random variables. Since voters only have 2 choices, then these are **Bernoulli** random variables. Additionally, since it can be assumed that voters think similarly and that one voter's choice does not affect another voter's choice, then these random variables are independent and identically distributed with parameter $p_A$. Note that $p_A = p(X_i = 1)$. For example, after picking a random sample of 1,000 people and asking each of them who they will vote for, the observed voting choices could be:\n",
    "\n",
    "$$\\mathcal{D} = \\{X_1 = 1,X_2 = 0,X_3 = 1,...,X_{1000} = 1\\}$$\n",
    "\n",
    "The maximum likelihood estimate for $p_A$ can then be computed by summing all the $X_i$'s for $i=1,2,...,1000$ and then dividing this summation by 1000. Mathematically, if $\\hat{\\Theta}=f(\\mathcal{D},1000)$ is a point estimator of $p_A$, then:\n",
    "\n",
    "$$\\hat{\\Theta} = \\frac{\\sum\\limits_{i = 1}^{1000} X_i}{1000}$$\n",
    "\n",
    "More generally, if $\\mathcal{D}$ is a sample of size $n$, then:\n",
    "\n",
    "$$\\hat{\\Theta} = \\frac{\\sum\\limits_{i = 1}^{n} X_i}{n}$$\n",
    "\n",
    "For example, if 800 out of 1,000 people said that they would vote for candidate A, then $\\hat{\\Theta} = 0.8$.\n",
    "\n",
    "Note, however, that since $\\hat{\\Theta}$ is a function of random variables, then it is also a random variable. This is because if you select a different sample of 1,000 people from the population, you may observe a different set of voting choices. For example, a new sample chosen from the population could be:\n",
    "\n",
    "$$\\mathcal{D} = \\{X_1 = 1,X_2 = 0,X_3 = 0,...,X_{1000} = 0\\}$$\n",
    "\n",
    "So, although $\\hat{\\Theta}$ is a point estimator, it will have different values for different samples. If a different sample of 1,000 people is taken from the population an infinite number of times and $\\hat{\\Theta}$ is computed each time, then, theoretically, the true value of $p_A$ is the mean of $\\hat{\\Theta}$:\n",
    "\n",
    "$$p_A = E\\left[\\hat{\\Theta}\\right]$$\n",
    "\n",
    "However, it is not practically possible to sample 1,000 different people an infinite number of times. Therefore, it would be helpful to compute an interval of values that $\\hat{\\Theta}$ could possibly take. This is called **interval estimation**.\n",
    "\n",
    "Since $\\hat{\\Theta}$ is random, then it has an associated probability distribution $p\\left(\\hat{\\Theta}\\right)$ called the **sampling distribution**. In this case, the sampling distribution is dependent on the sample size $n$, such that $p\\left(\\hat{\\Theta}\\right) = p\\left(\\hat{\\Theta};n\\right)$. Looking closer at the definition of $\\hat{\\Theta}$:\n",
    "\n",
    "$$\\hat{\\Theta} = \\frac{\\sum\\limits_{i = 1}^{1000} X_i}{1000}$$\n",
    "\n",
    "Since $\\sum\\limits_{i = 1}^{1000} X_i$ is a sum of i.i.d Bernoulli random variables, then:\n",
    "\n",
    "$$Y = \\sum\\limits_{i = 1}^{1000} X_i$$\n",
    "\n",
    "Is a binomial random variable with mean equal to:\n",
    "\n",
    "\\begin{align}\n",
    "E[Y] &= E\\left[\\sum\\limits_{i = 1}^{1000} X_i\\right] \\\\\n",
    "&= \\sum\\limits_{i = 1}^{1000} E[X_i] \\\\\n",
    "&= \\sum\\limits_{i = 1}^{1000} \\mu = 1000\\mu\n",
    "\\end{align}\n",
    "\n",
    "Where:\n",
    "\n",
    "$$E[X_1] = E[X_2] = ... = E[X_{1000}] = \\mu$$\n",
    "\n",
    "This means that the mean of $\\hat{\\Theta}$ is:\n",
    "\n",
    "$$E\\left[\\hat{\\Theta}\\right] = \\mu = p_A$$\n",
    "\n",
    "Additionally, the variance of $Y$ is:\n",
    "\n",
    "$$\n",
    "Var(Y) = Var(X_1 + X_2 + ... + X_{1000})\n",
    "$$\n",
    "\n",
    "Since $X_1,X_2,...,X_{1000}$ are independent and therefore uncorrelated, then the [variance of their sum is equal to the sum of their variances](https://en.wikipedia.org/wiki/Variance#Sum_of_uncorrelated_variables_(Bienaym%C3%A9_formula)):\n",
    "\n",
    "\\begin{equation}\n",
    "Var(X_1 + X_2 + ... + X_{1000}) = Var(X_1) + Var(X_2) + ... + Var(X_{1000})\n",
    "\\end{equation}\n",
    "\n",
    "So:\n",
    "\n",
    "\\begin{align}\n",
    "Var(X_1) &= E\\left[(X_1 - \\mu)^2\\right] \\\\\n",
    "&= E\\left[X_1^2 - 2X_1\\mu + \\mu^2\\right] \\\\\n",
    "&= E\\left[X_1^2\\right] - 2 \\mu E[X_1] + \\mu^2\n",
    "\\end{align}\n",
    "\n",
    "Using [LOTUS](https://en.wikipedia.org/wiki/Law_of_the_unconscious_statistician):\n",
    "\n",
    "$$\n",
    "E[X_1^2] = 0^2\\cdot p(X_1 = 0) + 1^2\\cdot p(X_1 = 1) = p(X_1 = 1) = \\mu\n",
    "$$\n",
    "\n",
    "So:\n",
    "$$\n",
    "Var(X_1) = \\mu - 2\\mu^2 + \\mu^2 = \\mu - \\mu^2 = \\mu(1-\\mu)\n",
    "$$\n",
    "\n",
    "Since:\n",
    "\n",
    "$$\n",
    "Var(Y) = \\sum_{i=1}^{1000} Var(X_i)\n",
    "$$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "Var(Y) = 1000\\mu(1-\\mu)\n",
    "$$\n",
    "\n",
    "Since:\n",
    "\n",
    "$$\\hat{\\Theta} = \\frac{Y}{1000}$$\n",
    "\n",
    "And for any random variable $W$:\n",
    "\n",
    "$$Var(aW) = a^2Var(W)$$\n",
    "\n",
    "Then:\n",
    "\n",
    "\\begin{align}\n",
    "Var\\left(\\hat{\\Theta}\\right) &= \\frac{Var(Y)}{1000^2} \\\\\n",
    "&= \\frac{1000\\mu(1-\\mu)}{1000^2} \\\\\n",
    "&= \\frac{\\mu(1-\\mu)}{1000} = \\frac{Var(X_i)}{1000}\n",
    "\\end{align}\n",
    "\n",
    "More generally, given a sample of $n$ i.i.d Bernoulli random variables each with a mean of $\\mu$, and the point estimator $\\hat{\\Theta}$ computes the sample mean, then:\n",
    "\n",
    "\\begin{align}\n",
    "E\\left[\\hat{\\Theta}\\right] &= \\mu \\\\\n",
    "Var\\left(\\hat{\\Theta}\\right) &= \\frac{\\mu(1-\\mu)}{n}\n",
    "\\end{align}\n",
    "\n",
    "The standard deviation of $\\hat{\\Theta}$ is called the **standard error** $\\sigma_{\\hat{\\Theta}}$:\n",
    "\n",
    "\\begin{align}\n",
    "\\sigma_{\\hat{\\Theta}} &= \\sqrt{Var\\left(\\hat{\\Theta}\\right)} \\\\\n",
    "&= \\sqrt{\\frac{\\mu(1-\\mu)}{n}} \\\\\n",
    "&= \\frac{\\sqrt{\\mu(1-\\mu)}}{\\sqrt{n}} \\\\\n",
    "&= \\frac{\\sigma_X}{\\sqrt{n}}\n",
    "\\end{align}\n",
    "\n",
    "Where $\\sigma_X$ is the standard deviation of $X_1,X_2,...,X_n$. Now, recall that the true value of $p_A$ is $E\\left[\\hat{\\Theta}\\right]$, which cannot be practically computed. Instead, the goal is to compute $a$ and $b$ such that:\n",
    "\n",
    "$$p\\left(E\\left[\\hat{\\Theta}\\right] - a<\\hat{\\Theta}<E\\left[\\hat{\\Theta}\\right] + b\\right) = c$$\n",
    "\n",
    "Which means that if you sample $n$ people from the population an infinite number of times, and each time you compute $\\hat{\\Theta}$, $\\hat{\\Theta}$ will be a maximum of $a$ or $b$ away from the true value $c\\%$ of the time. In other words, what values should be chosen for $a$ and $b$ such that $\\hat{\\Theta}$ lies in the interval $\\left[E\\left[\\hat{\\Theta}\\right] - a,E\\left[\\hat{\\Theta}\\right] + b\\right]$ with $c\\%$ **confidence**?\n",
    "\n",
    "Let's implement this in Python. First, sample 1,000 Bernoulli random variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 0 1\n",
      " 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 1 0 1 1 1 1 0 0 1 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1\n",
      " 0 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0 0 1\n",
      " 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0 1 0 1 1 0 1 1 1 0 1 1\n",
      " 0 1 1 1 0 0 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 1 1 0 0\n",
      " 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 1 1 0 0\n",
      " 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 1 1 1 1 0 1 0 1 1 1 1 0 1\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 0 0\n",
      " 1 0 1 0 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 1 1 1 0 0 0 1 1 0 1 0 1\n",
      " 0 0 1 0 0 0 1 0 1 1 1 0 1 0 1 0 1 1 1 0 0 1 1 0 0 1 1 1 0 1 0 1 1 1 0 1 1\n",
      " 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 0 1 0 0\n",
      " 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0 1 0 1 1 0 1\n",
      " 1 0 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 0 0 1 1 0 1 0 1 1 0 0 0 0 1 0 0 0 1 1\n",
      " 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 0 1 0 1 1 1 0 1 0 1 0 1 0 1 1 1\n",
      " 0 0 1 1 0 0 1 1 1 0 1 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0 0 0 0 1 1\n",
      " 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0\n",
      " 0 1 1 1 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 1 0\n",
      " 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 0 1 1 1 0 0 1 1 1 0 1 1 0 0 1 0 1\n",
      " 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 0 1 0\n",
      " 0 1 0 0 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 0 1 0 0 1 1 0 1 0 0 1 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 1 1 1 1 0\n",
      " 0 0 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 1 1 0 1 0 0 0 1 0 0 1 0\n",
      " 0 1 0 1 1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 0\n",
      " 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 0\n",
      " 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 1]\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import bernoulli\n",
    "\n",
    "# probability of success for each Bernoulli trial\n",
    "\n",
    "p = 0.5\n",
    "\n",
    "# number of samples\n",
    "\n",
    "num_samples = 1000\n",
    "\n",
    "# sample from Bernoulli distribution\n",
    "\n",
    "D = bernoulli.rvs(p = p,\n",
    "                  loc = 0,\n",
    "                  size = num_samples,\n",
    "                  random_state = None)\n",
    "\n",
    "print(D)\n",
    "print(D.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, compute $Y$, the binomial random variable that is the sum of the 1,000 Bernoulli random variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496\n"
     ]
    }
   ],
   "source": [
    "Y = D.sum()\n",
    "\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are a large number of samples available ($n=1000$), then $Y$ can be approximated by the following [normal distribution](https://en.wikipedia.org/wiki/Binomial_distribution#Normal_approximation):\n",
    "\n",
    "$$Y \\sim \\mathcal{N}(np_A,np_A(1-p_A))$$\n",
    "\n",
    "This can also be justified by the [central limit theorem](https://en.wikipedia.org/wiki/Central_limit_theorem). Since:\n",
    "\n",
    "$$\\hat{\\Theta} = \\frac{Y}{n}$$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\\hat{\\Theta} \\sim \\mathcal{N}\\left(p_A,\\frac{p_A(1-p_A)}{n}\\right)$$\n",
    "\n",
    "**----------------------------------------------------------------------------------**\n",
    "\n",
    "\n",
    "Now suppose that you want to find the 95% confidence interval for $\\hat{\\Theta}$. This means that you want to find $a$ and $b$ such that:\n",
    "\n",
    "$$p\\left(a<\\hat{\\Theta}<b\\right) = 0.95$$\n",
    "\n",
    "Since:\n",
    "\n",
    "$$p\\left(a<\\hat{\\Theta}<b\\right) = 1-p\\left(\\hat{\\Theta} < a \\cup \\hat{\\Theta} > b\\right)$$\n",
    "\n",
    "Since the intervals $[-\\infty,a]$ and $[b,\\infty]$ are disjoint, then:\n",
    "\n",
    "$$\n",
    "1-p\\left(\\hat{\\Theta} < a \\cup \\hat{\\Theta} > b\\right) = 1 - p\\left(\\hat{\\Theta} < a\\right) - p\\left(\\hat{\\Theta} > b\\right)\n",
    "$$\n",
    "\n",
    "Since the normal distribution is symmetric about $E\\left[\\hat{\\Theta}\\right]=p$, then:\n",
    "\n",
    "$$\n",
    "p\\left(\\hat{\\Theta} < a\\right) = p\\left(\\hat{\\Theta} > b\\right)\n",
    "$$\n",
    "\n",
    "And therefore:\n",
    "\n",
    "$$\n",
    "1 - p\\left(\\hat{\\Theta} < a\\right) - p\\left(\\hat{\\Theta} > b\\right) = 1 - 2p\\left(\\hat{\\Theta} < a\\right)\n",
    "$$\n",
    "\n",
    "Since the normal distribution is continuous:\n",
    "\n",
    "$$\n",
    "p\\left(\\hat{\\Theta} < a\\right) = p\\left(\\hat{\\Theta} \\leq a\\right)\n",
    "$$\n",
    "\n",
    "Finally, the equation is:\n",
    "\n",
    "$$\n",
    "1 - 2p\\left(\\hat{\\Theta} \\leq a\\right) = 0.95\n",
    "$$\n",
    "\n",
    "Re-arranging:\n",
    "\n",
    "$$\n",
    "p\\left(\\hat{\\Theta} \\leq a\\right) = 0.025\n",
    "$$\n",
    "\n",
    "Notice that the left hand size of the equation is the cumulative distribution function of $\\hat{\\Theta}$ evaluated at $a$. Therefore, the inverse normal cumulative distribution function can be used to find $a$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
